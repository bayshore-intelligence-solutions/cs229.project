{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from keras.datasets import mnist\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "import keras.backend as K\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from lstm_utils import minutizer, combine_ts, preprocess_2_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-33b6104eefdc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def load_data():   \n",
    "    lookback = 24\n",
    "    ground_features = 4\n",
    "    dropout_rate = float(0.1)\n",
    "    percentile = 10\n",
    "    learning_rate = float(0.0001)\n",
    "    stocks = ['ACN', 'AMAT',  'CDNS', 'IBM', 'INTU', 'LRCX', 'NTAP', 'VRSN', 'WU', 'XLNX']\n",
    "    data = combine_ts(stocks)\n",
    "    data = minutizer(data, split=5)\n",
    "    data, _ = preprocess_2_multi(data, stocks)\n",
    "\n",
    "    # Transform data\n",
    "    n, d = data.shape\n",
    "    amount_of_stocks = int(d/ground_features)\n",
    "    train_val_test_split = {'train': 0.7, 'val': 0.85, 'test': 1}\n",
    "\n",
    "    new_n = (n - lookback) * amount_of_stocks\n",
    "\n",
    "    X = np.zeros((new_n, lookback, ground_features))\n",
    "    Y = np.zeros((new_n, 1))\n",
    "\n",
    "    for i in range(n - lookback):\n",
    "        for j in range(amount_of_stocks):\n",
    "            idx = i * amount_of_stocks + j\n",
    "            for k in range(ground_features):\n",
    "                col = j * ground_features + k\n",
    "                X[idx, :, k] = data.iloc[i: (i + lookback), col]\n",
    "            Y[idx] = data.iloc[i + lookback, ground_features * j]\n",
    "\n",
    "    X_train = X[0: int(new_n * train_val_test_split['train'])]\n",
    "    y_train = Y[0: int(new_n * train_val_test_split['train'])]\n",
    "\n",
    "    X_val = X[int(new_n * train_val_test_split['train']): int(new_n * train_val_test_split['val'])]\n",
    "    y_val = Y[int(new_n * train_val_test_split['train']): int(new_n * train_val_test_split['val'])]\n",
    "\n",
    "    X_test = X[int(new_n * train_val_test_split['val']): int(new_n * train_val_test_split['test'])]\n",
    "    y_test = Y[int(new_n * train_val_test_split['val']): int(new_n * train_val_test_split['test'])]\n",
    "    return X_train, y_train, X_val, y_val\n",
    "\n",
    "print(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(X_train, y_train, X_val, y_val):\n",
    "    lookback = 24\n",
    "    ground_features = 4\n",
    "    dropout_rate = float(0.1)\n",
    "    percentile = 10\n",
    "    learning_rate = float(0.0001)\n",
    "    model = Sequential()\n",
    "    # Adding layers. LSTM(n) --> Dropout(p)\n",
    "    model.add(LSTM(units={{choice([20,30,40])}}, return_sequences=True, use_bias=True, input_shape=(lookback, ground_features)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(LSTM(units=10, use_bias=False))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(units=1, activation='linear', use_bias=True))\n",
    "\n",
    "    # Optimizer\n",
    "    adam_opt = optimizers.adam(lr=learning_rate)\n",
    "\n",
    "    # Compile\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "    # Fit\n",
    "    result = model.fit(X_train, y_train, epochs=2, batch_size=96, validation_data=(X_val, y_val))\n",
    "\n",
    "    #get the highest validation accuracy of the training epochs\n",
    "    validation_acc = result.history['val_acc']\n",
    "    print('Best validation acc of epoch:', validation_acc)\n",
    "    return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "from __future__ import print_function\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.datasets import mnist\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.core import Dense, Dropout, Activation\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.utils import np_utils\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Dense, LSTM, Dropout\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import keras.backend as K\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import optimizers\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import random\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from lstm_utils import minutizer, combine_ts, preprocess_2_multi\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'units': hp.choice('units', [20,30,40]),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "   1: \n",
      "   2: lookback = 24\n",
      "   3: ground_features = 4\n",
      "   4: dropout_rate = float(0.1)\n",
      "   5: percentile = 10\n",
      "   6: learning_rate = float(0.0001)\n",
      "   7: stocks = ['ACN', 'AMAT',  'CDNS', 'IBM', 'INTU', 'LRCX', 'NTAP', 'VRSN', 'WU', 'XLNX']\n",
      "   8: data = combine_ts(stocks)\n",
      "   9: data = minutizer(data, split=5)\n",
      "  10: data, _ = preprocess_2_multi(data, stocks)\n",
      "  11: \n",
      "  12: # Transform data\n",
      "  13: n, d = data.shape\n",
      "  14: amount_of_stocks = int(d/ground_features)\n",
      "  15: train_val_test_split = {'train': 0.7, 'val': 0.85, 'test': 1}\n",
      "  16: \n",
      "  17: new_n = (n - lookback) * amount_of_stocks\n",
      "  18: \n",
      "  19: X = np.zeros((new_n, lookback, ground_features))\n",
      "  20: Y = np.zeros((new_n, 1))\n",
      "  21: \n",
      "  22: for i in range(n - lookback):\n",
      "  23:     for j in range(amount_of_stocks):\n",
      "  24:         idx = i * amount_of_stocks + j\n",
      "  25:         for k in range(ground_features):\n",
      "  26:             col = j * ground_features + k\n",
      "  27:             X[idx, :, k] = data.iloc[i: (i + lookback), col]\n",
      "  28:         Y[idx] = data.iloc[i + lookback, ground_features * j]\n",
      "  29: \n",
      "  30: X_train = X[0: int(new_n * train_val_test_split['train'])]\n",
      "  31: y_train = Y[0: int(new_n * train_val_test_split['train'])]\n",
      "  32: \n",
      "  33: X_val = X[int(new_n * train_val_test_split['train']): int(new_n * train_val_test_split['val'])]\n",
      "  34: y_val = Y[int(new_n * train_val_test_split['train']): int(new_n * train_val_test_split['val'])]\n",
      "  35: \n",
      "  36: X_test = X[int(new_n * train_val_test_split['val']): int(new_n * train_val_test_split['test'])]\n",
      "  37: y_test = Y[int(new_n * train_val_test_split['val']): int(new_n * train_val_test_split['test'])]\n",
      "  38: \n",
      "  39: \n",
      "  40: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3:     lookback = 24\n",
      "   4:     ground_features = 4\n",
      "   5:     dropout_rate = float(0.1)\n",
      "   6:     percentile = 10\n",
      "   7:     learning_rate = float(0.0001)\n",
      "   8:     model = Sequential()\n",
      "   9:     # Adding layers. LSTM(n) --> Dropout(p)\n",
      "  10:     model.add(LSTM(units=space['units'], return_sequences=True, use_bias=True, input_shape=(lookback, ground_features)))\n",
      "  11:     model.add(Dropout(dropout_rate))\n",
      "  12: \n",
      "  13:     model.add(LSTM(units=10, use_bias=False))\n",
      "  14:     model.add(Dropout(dropout_rate))\n",
      "  15: \n",
      "  16:     # Output layer\n",
      "  17:     model.add(Dense(units=1, activation='linear', use_bias=True))\n",
      "  18: \n",
      "  19:     # Optimizer\n",
      "  20:     adam_opt = optimizers.adam(lr=learning_rate)\n",
      "  21: \n",
      "  22:     # Compile\n",
      "  23:     model.compile(optimizer='adam', loss='mean_squared_error')\n",
      "  24: \n",
      "  25:     # Fit\n",
      "  26:     result = model.fit(X_train, y_train, epochs=2, batch_size=96, validation_data=(X_val, y_val))\n",
      "  27: \n",
      "  28:     #get the highest validation accuracy of the training epochs\n",
      "  29:     validation_acc = result.history['val_acc']\n",
      "  30:     print('Best validation acc of epoch:', validation_acc)\n",
      "  31:     return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}\n",
      "  32: \n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    best_run, best_model = optim.minimize(model=create_model,\n",
    "                                          data=load_data,\n",
    "                                          algo=tpe.suggest,\n",
    "                                          max_evals=5,\n",
    "                                          trials=Trials(),\n",
    "                                            notebook_name = 'hyperas_lstm')\n",
    "    X_train, y_train, X_val, y_val = data()\n",
    "    print(\"Evalutation of best performing model:\")\n",
    "    print(best_model.evaluate(X_val, y_val))\n",
    "    print(\"Best performing model chosen hyper-parameters:\")\n",
    "    print(best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
